"""
Report Generator

Generates comprehensive verification reports with citations.

Copyright (C) 2025
License: GPL-3.0-or-later
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List

from nuremberg_analysis.claim_verifier import VerificationResult


class ReportGenerator:
    """Generates comprehensive verification reports"""

    def __init__(self, output_dir: Path = Path("./reports")):
        self.output_dir = output_dir
        self.output_dir.mkdir(exist_ok=True, parents=True)

    def generate_comprehensive_report(
        self, results: List[VerificationResult], output_format: str = "markdown"
    ) -> Path:
        """
        Generate comprehensive verification report

        Args:
            results: List of verification results
            output_format: "markdown", "html", or "json"

        Returns:
            Path to generated report file
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if output_format == "markdown":
            return self._generate_markdown_report(results, timestamp)
        if output_format == "html":
            return self._generate_html_report(results, timestamp)
        if output_format == "json":
            return self._generate_json_report(results, timestamp)
        raise ValueError(f"Unknown format: {output_format}")

    def _generate_markdown_report(self, results: List[VerificationResult], timestamp: str) -> Path:
        """Generate Markdown report"""
        report_path = self.output_dir / f"chomsky_verification_report_{timestamp}.md"

        with open(report_path, "w", encoding="utf-8") as f:
            # Header
            f.write("# Verification Report: Chomsky's 'If the Nuremberg Laws were Applied...'\n\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")

            # Executive Summary
            f.write("## Executive Summary\n\n")
            summary = self._generate_summary(results)
            f.write(summary)
            f.write("\n\n---\n\n")

            # Detailed Results by Category
            f.write("## Detailed Verification Results\n\n")

            # Group by category
            by_category = {}
            for result in results:
                category = result.claim.category
                if category not in by_category:
                    by_category[category] = []
                by_category[category].append(result)

            for category, category_results in sorted(by_category.items()):
                f.write(f"### {category}\n\n")

                for result in category_results:
                    self._write_claim_result_markdown(f, result)
                    f.write("\n")

            # Citations
            f.write("---\n\n")
            f.write("## Citations\n\n")
            all_citations = set()
            for result in results:
                all_citations.update(result.citations)

            for i, citation in enumerate(sorted(all_citations), 1):
                f.write(f"{i}. {citation}\n")

            # Methodology
            f.write("\n---\n\n")
            f.write("## Methodology\n\n")
            f.write("This report was generated by automated analysis of documents from the ")
            f.write("Harvard Law School Library's Nuremberg Trials Project. ")
            f.write("Documents were searched, parsed, and analyzed to verify claims made ")
            f.write("in Noam Chomsky's essay.\n\n")
            f.write("**Note:** This is an automated analysis. Full verification may require ")
            f.write(
                "manual review of original documents and consultation of additional sources.\n\n"
            )

            # Disclaimer
            f.write("---\n\n")
            f.write("## Disclaimer\n\n")
            f.write("This report was generated with the assistance of Cursor.AI for user ")
            f.write("ajlennon (Alex J Lennon, ajlennon@dynamicdevices.co.uk).\n")
            f.write("The analysis is based on publicly available documents from the ")
            f.write("Harvard Law School Library's Nuremberg Trials Project.\n")
            f.write("Users should verify all claims by consulting original documents.\n")

        return report_path

    def _write_claim_result_markdown(self, f, result: VerificationResult):
        """Write a single claim result in Markdown format"""
        claim = result.claim

        f.write(f"#### Claim {claim.id}: {claim.category}\n\n")
        f.write(f"**Claim:** {claim.claim_text}\n\n")
        f.write(f"**Context:** {claim.context}\n\n")

        # Status badge
        status_emoji = {
            "verified": "âœ…",
            "partially_verified": "âš ï¸",
            "contradicted": "âŒ",
            "insufficient_evidence": "â“",
            "not_found": "ðŸ”",
        }
        emoji = status_emoji.get(result.status, "â“")
        f.write(f"**Status:** {emoji} {result.status.replace('_', ' ').title()} ")
        f.write(f"(Confidence: {result.confidence:.1%})\n\n")

        # Supporting Evidence
        if result.supporting_evidence:
            f.write("**Supporting Evidence:**\n\n")
            for i, (doc, excerpt) in enumerate(result.supporting_evidence[:5], 1):  # Limit to 5
                f.write(f"{i}. **{doc.title}** ({doc.trial}, {doc.document_type})\n")
                f.write(f"   > {excerpt[:500]}...\n")
                f.write(f"   Source: {doc.url}\n\n")

        # Contradicting Evidence
        if result.contradicting_evidence:
            f.write("**Contradicting Evidence:**\n\n")
            for i, (doc, excerpt) in enumerate(result.contradicting_evidence[:5], 1):
                f.write(f"{i}. **{doc.title}** ({doc.trial}, {doc.document_type})\n")
                f.write(f"   > {excerpt[:500]}...\n")
                f.write(f"   Source: {doc.url}\n\n")

        # Notes
        if result.notes:
            f.write(f"**Notes:** {result.notes}\n\n")

        # Citations
        if result.citations:
            f.write("**References:**\n")
            for citation in result.citations[:10]:  # Limit citations
                f.write(f"- {citation}\n")
            f.write("\n")

    def _generate_summary(self, results: List[VerificationResult]) -> str:
        """Generate executive summary"""
        total = len(results)
        verified = sum(1 for r in results if r.status == "verified")
        partial = sum(1 for r in results if r.status == "partially_verified")
        contradicted = sum(1 for r in results if r.status == "contradicted")
        insufficient = sum(1 for r in results if r.status == "insufficient_evidence")
        not_found = sum(1 for r in results if r.status == "not_found")

        summary = f"""
**Total Claims Analyzed:** {total}

**Verification Status:**
- âœ… Verified: {verified} ({verified/total*100:.1f}%)
- âš ï¸ Partially Verified: {partial} ({partial/total*100:.1f}%)
- âŒ Contradicted: {contradicted} ({contradicted/total*100:.1f}%)
- â“ Insufficient Evidence: {insufficient} ({insufficient/total*100:.1f}%)
- ðŸ” Not Found: {not_found} ({not_found/total*100:.1f}%)

**Average Confidence:** {sum(r.confidence for r in results) / total:.1%}

**Key Findings:**
"""
        # Add key findings based on results
        high_confidence_verified = [
            r for r in results if r.status == "verified" and r.confidence > 0.7
        ]
        if high_confidence_verified:
            summary += f"- {len(high_confidence_verified)} claims verified with high confidence\n"

        return summary

    def _generate_html_report(self, results: List[VerificationResult], timestamp: str) -> Path:
        """Generate HTML report"""
        report_path = self.output_dir / f"chomsky_verification_report_{timestamp}.html"

        # Convert markdown to HTML (simplified version)
        # In production, use a proper markdown-to-HTML converter
        md_path = self._generate_markdown_report(results, timestamp)

        # For now, just create a simple HTML wrapper
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("<!DOCTYPE html>\n<html>\n<head>\n")
            f.write('<meta charset="utf-8">\n')
            f.write("<title>Chomsky Verification Report</title>\n")
            f.write(
                "<style>body { font-family: sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; }</style>\n"
            )
            f.write("</head>\n<body>\n")
            f.write(
                f'<iframe src="{md_path.name}" style="width: 100%; height: 100vh; border: none;"></iframe>\n'
            )
            f.write("</body>\n</html>\n")

        return report_path

    def _generate_json_report(self, results: List[VerificationResult], timestamp: str) -> Path:
        """Generate JSON report"""
        report_path = self.output_dir / f"chomsky_verification_report_{timestamp}.json"

        report_data = {
            "generated": datetime.now().isoformat(),
            "total_claims": len(results),
            "summary": {
                "verified": sum(1 for r in results if r.status == "verified"),
                "partially_verified": sum(1 for r in results if r.status == "partially_verified"),
                "contradicted": sum(1 for r in results if r.status == "contradicted"),
                "insufficient_evidence": sum(
                    1 for r in results if r.status == "insufficient_evidence"
                ),
                "not_found": sum(1 for r in results if r.status == "not_found"),
                "average_confidence": (
                    sum(r.confidence for r in results) / len(results) if results else 0
                ),
            },
            "results": [
                {
                    "claim_id": r.claim.id,
                    "category": r.claim.category,
                    "claim_text": r.claim.claim_text,
                    "status": r.status,
                    "confidence": r.confidence,
                    "supporting_evidence_count": len(r.supporting_evidence),
                    "contradicting_evidence_count": len(r.contradicting_evidence),
                    "citations": r.citations,
                    "notes": r.notes,
                }
                for r in results
            ],
        }

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        return report_path
